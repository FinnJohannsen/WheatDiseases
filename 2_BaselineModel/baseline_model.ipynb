{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model\n",
    "\n",
    "## Table of Contents\n",
    "1. [Model Choice](#model-choice)\n",
    "2. [Feature Selection](#feature-selection)\n",
    "3. [Implementation](#implementation)\n",
    "4. [Evaluation](#evaluation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Choice\n",
    "\n",
    "[Explain why you've chosen a particular model as the baseline. This could be a simple statistical model or a basic machine learning model. Justify your choice.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "[Indicate which features from the dataset you will be using for the baseline model, and justify your selection.]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "[Implement your baseline model here.]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the baseline model\n",
    "# Your implementation code here\n",
    "# Define the model\n",
    "import tensorflow as tf\n",
    "#from tensorflow.keras import layers\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the folders containing the image data\n",
    "train_data_dir = '../Dataset/cleaned_scaled_split/train/'\n",
    "validation_data_dir = '../Dataset/cleaned_scaled_split/val/'\n",
    "test_data_dir = '../Dataset/cleaned_scaled_split/test/'\n",
    "\n",
    "# Set the parameters for image data generation\n",
    "batch_size = 64\n",
    "img_height = 256\n",
    "img_width = 256\n",
    "# Load the training data from the folders\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=train_data_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',\n",
    "    batch_size=64,\n",
    "    image_size=(256, 256))\n",
    "\n",
    "\n",
    "# Load the validation data from the folders\n",
    "validation_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=validation_data_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',\n",
    "    batch_size=64,\n",
    "    image_size=(256, 256))\n",
    "\n",
    "# Load the validation data from the folders\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=test_data_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    color_mode='rgb',\n",
    "    batch_size=64,\n",
    "    image_size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Get an element from the train dataset\n",
    "# element = next(iter(train_ds.take(1)))\n",
    "\n",
    "# # Access the input and target tensors\n",
    "# input_tensor, target_tensor = element\n",
    "\n",
    "# # Print the shapes of the tensors\n",
    "# print(\"Input tensor shape:\", input_tensor.shape)\n",
    "# print(\"Target tensor shape:\", target_tensor.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the network using the loaded data\n",
    "import time\n",
    "name = \"training_\" + time.strftime(\"%Y%m%d-%H%M\")\n",
    "csv_logger =  tf.keras.callbacks.CSVLogger(name+'.csv', append=True, separator=';')\n",
    "model.fit(train_ds, epochs=10, validation_data=validation_ds, callbacks=[csv_logger])\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model parameters to a file\n",
    "#model.save_weights('baseline_model_weights_01.ckpt')\n",
    "model.save('baseline_model_10_epoch_tvt_split.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "train_dir = '../Dataset/train_cleaned_scaled/train/'\n",
    "\n",
    "datadirs = os.listdir(train_dir)\n",
    "print(datadirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_acc = model.history.history['accuracy']\n",
    "plt.figure(figsize=(8, 4), dpi=150)\n",
    "plt.plot(train_acc)\n",
    "plt.grid()\n",
    "plt.xticks(range(0, 10))\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "[Clearly state what metrics you will use to evaluate the model's performance. These metrics will serve as a starting point for evaluating more complex models later on.]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "model = tf.keras.models.load_model('baseline_model_10_epoch_tvt_split.keras')\t\n",
    "\n",
    "class_correct = [0]*10\n",
    "class_counters = [0]*10\n",
    "for batch in test_ds:\n",
    "    images, labels = batch\n",
    "    predictions = model.predict(images)\n",
    "    y_pred_classes = np.argmax(predictions, axis=1)\n",
    "    print(np.mean(y_pred_classes==labels.numpy()))\n",
    "    for i in range(10):\n",
    "        class_correct[i] += np.sum(y_pred_classes[labels.numpy()==i] == i)\n",
    "        class_counters[i] += np.sum(labels.numpy()==i)\n",
    "\n",
    "calss_accuracy = [class_correct[i]/class_counters[i] for i in range(10)]\n",
    "\n",
    "\n",
    "\n",
    "# # For a regression problem, you might use:\n",
    "# # mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# # Your evaluation code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the class labels\n",
    "class_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# Plot the bar chart\n",
    "plt.figure(figsize=(8, 4), dpi=150)\n",
    "plt.grid()\n",
    "plt.bar(class_labels, np.asarray(calss_accuracy)*100)\n",
    "\n",
    "# Add labels and title\n",
    "#plt.xlabel('Class')\n",
    "plt.ylabel('Accuracy in %')\n",
    "plt.title('Accuracy of the baseline model on the test data for each class')\n",
    "\n",
    "plt.ylim(0, 100)\n",
    "plt.xticks(class_labels,datadirs, rotation=45, ha='right')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
